{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rebecca Black â€¢ March 30, 2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains code written for my analysis of New York Subway ridership data.\n",
    "I performed a variety of analyses on these data, which included incorporating weather\n",
    "data and doing a linear regression analysis using gradient descent. This analysis is\n",
    "presented in \"unexecuted\" form, as a code sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I use pandasql to select out and add up the total # of rainy days in the weather dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import pandasql\n",
    "\n",
    "weather_data = pandas.read_csv(weather_underground.csv)\n",
    "\n",
    "q =\n",
    "SELECT sum(rain)\n",
    "FROM weather_data\n",
    "WHERE cast(rain as integer) = 1\n",
    "    \n",
    "#Execute the SQL command against the DataFrame\n",
    "rainy_days = pandasql.sqldf(q.lower(), locals())\n",
    "print rainy_days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I use pandasql to subset the data according to the boolean 'fog', and return the\n",
    "maximum max temperature for the foggy and non-foggy days in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weather_data = pandas.read_csv(weather_underground.csv)\n",
    "\n",
    "q =\n",
    "SELECT fog, max(maxtempi)\n",
    "FROM weather_data\n",
    "GROUP BY fog\n",
    "\n",
    "#Execute the SQL command against the DataFrame\n",
    "foggy_days = pandasql.sqldf(q.lower(), locals())\n",
    "print foggy_days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I look at the weekends. The aim here was to determine the average mean temperature\n",
    "across all the weekend days in the dataset. It was necessary to convert the dates to\n",
    "days of the week to restrict the selection to weekends:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weather_data = pandas.read_csv(weather_underground.csv)\n",
    "\n",
    "q =\n",
    "SELECT avg(meantempi)\n",
    "FROM weather_data\n",
    "WHERE cast(strftime('%w', date) as integer)=0 OR cast(strftime('%w', date) as integer)=6\n",
    "\n",
    "#Execute the SQL command against the DataFrame\n",
    "mean_temp_weekends = pandasql.sqldf(q.lower(), locals())\n",
    "print mean_temp_weekends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I look at a more complex query. Here I look at the average minimum temperature\n",
    "on rainy days where the minimum temperature for that day was more than 55 degrees:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weather_data = pandas.read_csv(weather_underground.csv)\n",
    "\n",
    "q =\n",
    "SELECT avg(mintempi)\n",
    "FROM weather_data\n",
    "WHERE cast(rain as integer) = 1 AND cast(mintempi as integer) > 55\n",
    "GROUP BY rain\n",
    "    \n",
    "#Execute the SQL command against the DataFrame\n",
    "avg_min_temp_rainy = pandasql.sqldf(q.lower(), locals())\n",
    "print avg_min_temp_rainy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I turn to the actual subway turnstile data. Before proceeding with any\n",
    "analysis, it is necessary to rewrite the rows of the dataset so that we have \n",
    "only one datapoint per row (the raw dataset has five datapoints per row.) \n",
    "This requires splitting each line appropriately, taking into account that the \n",
    "first three elements of each line in the raw dataset should be repeated for \n",
    "each observation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "for name in filenames:\n",
    "    f_in = open(name, 'r')\n",
    "    f_out = open(\"updated_\" + name, 'w')\n",
    "\n",
    "    reader = csv.reader(f_in, delimiter=',')\n",
    "    writer = csv.writer(f_out, delimiter=',')\n",
    "\n",
    "    for line in reader:\n",
    "        elements = len(line)\n",
    "        num_lines = (elements - 3) / 5\n",
    "        for i in range(num_lines):\n",
    "            line_out = [line[0], line[1], line[2], line[3+5*i], line[4+5*i], line[5+5*i], line[6+5*i], line[7+5*i]]\n",
    "            writer.writerow(line_out)\n",
    "\n",
    "    f_in.close()\n",
    "    f_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I write a function that combines a group of files into a single file\n",
    "to facilitate easier modeling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_master_turnstile_file(filenames, output_file):\n",
    "    with open(output_file, 'w') as master_file:\n",
    "        master_file.write('C/A,UNIT,SCP,DATEn,TIMEn,DESCn,ENTRIESn,EXITSn\\n')\n",
    "        for filename in filenames:\n",
    "            with open(filename) as infile:\n",
    "                for line in infile:\n",
    "                    master_file.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I'm subsetting the data according to a specific attribute of DESCn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filtered = pandas.read_csv(filename)\n",
    "filtered_df = pandas.DataFrame(filename)\n",
    "\n",
    "q=\n",
    "SELECT * \n",
    "FROM filtered_df \n",
    "WHERE DESCn like 'REGULAR'\n",
    "\n",
    "turnstile_data = pandasql.sqldf(q.lower(), locals())\n",
    "return turnstile_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I use the cumulative entries and exits to produce a calculated variable\n",
    "that gives us the number of entries per hour:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['ENTRIESn_hourly'] = (df['ENTRIESn'] - df['ENTRIESn'].shift(1)).fillna(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I do the same to produce a calculated variable that gives us the number of\n",
    "exits per hour:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['EXITSn_hourly'] = (df['EXITSn'] - df['EXITSn'].shift(1)).fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I write a function to extract the hour portion from the time\n",
    "variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def time_to_hour(time):\n",
    "    hour=time[0:time.find(':')]\n",
    "    hour=int(hour)\n",
    "    return hour\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I reformat the dates in the subway dataset so they match the format\n",
    "from the weather dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def reformat_subway_dates(date):\n",
    "    t = datetime.strptime(date, '%m-%d-%y')\n",
    "    date_formatted = t.strftime('%Y-%m-%d')\n",
    "    return date_formatted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next is a histogram of the hourly entries grouped according to rain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "turnstile_weather_rainy=turnstile_weather[turnstile_weather[\"rain\"] == 1]\n",
    "turnstile_weather_norain=turnstile_weather[turnstile_weather[\"rain\"] == 0]\n",
    "    \n",
    "plt.figure()\n",
    "turnstile_weather_rainy['ENTRIESn_hourly'].hist()\n",
    "turnstile_weather_norain['ENTRIESn_hourly'].hist()\n",
    "return plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I perform a Mann-Whitney U test to determine whether subway ridership\n",
    "is the same on rainy days as it is on non-rainy days:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "import scipy.stats\n",
    "\n",
    "turnstile_weather_rainy=turnstile_weather[turnstile_weather[\"rain\"] == 1]\n",
    "turnstile_weather_norain=turnstile_weather[turnstile_weather[\"rain\"] == 0]\n",
    "\n",
    "with_rain_mean=np.mean(turnstile_weather_rainy['ENTRIESn_hourly'])\n",
    "without_rain_mean=np.mean(turnstile_weather_norain['ENTRIESn_hourly'])\n",
    "\n",
    "#Perform a Mann-Whitney U test (null hypothesis: two populations are from same distribution)\n",
    "#U is the test statistic, p is the one sided p-value for the test\n",
    "U,p=scipy.stats.mannwhitneyu(turnstile_weather_rainy['ENTRIESn_hourly'],turnstile_weather_norain['ENTRIESn_hourly'])\n",
    "    \n",
    "print with_rain_mean, without_rain_mean, U, p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've omitted the code for the regression, but the next step is making a histogram\n",
    "of the residuals for the regression to check that they do not exhibit a pattern:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "(turnstile_weather['ENTRIESn_hourly'] - predictions).hist()\n",
    "return plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, here is a function that computes the R^2 of the residuals from the regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "def compute_r_squared(data, predictions):\n",
    "    difference_data_pred=data-predictions\n",
    "    difference_data_avg=data-np.mean(data)\n",
    "    r_squared=1-(np.dot(difference_data_pred,difference_data_pred)/np.dot(difference_data_avg,difference_data_avg))\n",
    "    \n",
    "    return r_squared"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
